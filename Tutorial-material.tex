\section{Introduction}

Welcome to this training course on the responsible use of Artificial Intelligence (AI) at the company

The term Artificial Intelligence refers to computer systems that can perform tasks typically requiring human intelligence, such as understanding language, recognizing patterns, and making decisions. 
While the AI field has many years of research and development behind it, today‚Äôs increased popularity is largely driven by generative AI models‚Äîsystems that can create new content like text, images, and code based on the patterns they‚Äôve learned from vast amounts of data. You‚Äôve probably heard of and used tools like ChatGPT and Copilot‚Äîhere we‚Äôll learn how to use them effectively.


\subsection{Learning Objectives}
By the end of this course, you will be able to:
\begin{itemize}
Understand what LLMs are and their key capabilities and limitations
\item Apply responsible practices when using AI tools in your work
\item Craft effective prompts that enhance rather than replace critical thinking
\item Navigate ethical considerations including bias, privacy, and environmental impact

\end{itemize}

\section{What are LLMs?}


\textbf{NoteKey Takeaways}
\begin{itemize}
\item LLMs are mathematical models of language that maps similar words to nearby positions in a conceptual space
\item They predict which words are most likely to follow a given input, or prompt, based on patterns learned from vast amounts of text
\item They work by pattern matching, not true understanding, therefore they are not infallible sources of truth
\item Always verify important information from authoritative sources
\item Be aware of bias in AI outputs and actively check for it
\item Use critical thinking - if something sounds too precise or extreme, investigate further

\end{itemize}

\subsection{Natural Language Processing}
Natural Language Processing (NLP) is a branch of Artificial Intelligence that serves as the foundational technology that enables Large Language Models to understand and generate human language. Natural language is inherently ambiguous and contextual.

Consider the sentence

‚ÄúI saw the man with the telescope‚Äù.

This could mean:
\begin{itemize}
\item you used a telescope to see the man,
\item you saw a man carrying a telescope.
\end{itemize}
At its core, NLP transforms words, phrases, and sentences into numerical representations called embeddings‚Äîhigh-dimensional vectors that capture semantic meaning and relationships between linguistic elements. These embedding spaces are constructed so that words or phrases with similar meanings are positioned closer together in the vector space, while semantically different concepts are farther apart. For example, ‚Äúking‚Äù and ‚Äúman‚Äù would be nearby vectors, as would ‚Äúqueen‚Äù and ‚Äúwoman‚Äù but ‚Äúman‚Äù and ‚Äúwoman‚Äù would be distant. This mathematical representation of language allows to perform some complex reasoning about text by manipulating these vectors through neural network operations.

\subsection{The Large Language Model Revolution}
Large Language Models represented a paradigm shift in learning language patterns from the Internet, books, and other vast text sources. Built on transformer architecture(https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)), LLMs focus on relevant parts of the input when processing words (tokens) or phrases, enabling understanding of long-range dependencies that earlier models missed. While you don‚Äôt need to understand the mathematics, the key insight is that LLMs work by finding patterns and relationships between concepts.

Let‚Äôs assume that we want to embed the words of this sentence:

The Jean Golding Institute is a central hub for data science and data-intensive research at the University of Bristol. We connect a multidisciplinary community of experts across the University and beyond.

Our chatbot will break the sentence in tokens of one or less words and assign each a numeric identifier, as depicted below. A rule of thumb is that one token generally corresponds to 4 characters of text for common English.

https://platform.openai.com/tokenizer

Each of these tokens will have a mapping in the embedding space of our LLM model.

What makes LLMs ‚Äúlarge‚Äù is their training scale, the exposure to hundreds of billions of words from diverse sources allows them to internalize grammar, vocabulary, world knowledge, and reasoning patterns. The training process is elegantly simple: models learn by predicting the next word in sequences, adjusting internal parameters based on prediction errors. This forces development of sophisticated internal representations of language and knowledge.

LLMs fundamentally change how we approach NLP tasks. Instead of building specialized systems for each application, a single LLM can handle multiple tasks through different prompting strategies. The same model that excels at translation can also summarize documents, answer questions, or generate creative content without additional training.

The workplace implications are profound. Tasks requiring specialized software and technical expertise become accessible through natural language interaction. Document analysis, content generation, customer service automation, and data extraction are now available to non-technical users through conversational interfaces.

\subsection{What can LLMs do?}
LLMs can help with:
\begin{itemize}
\item Writing assistance: Drafting emails, reports, and documents
\item Summarization: Condensing long texts into key points
\item Translation: Converting between languages
\item Question answering: Providing information on various topics
\item Code generation: Writing and explaining programming code
\item Creative tasks: Brainstorming ideas and creative writing
\end{itemize}

\subsection{Exercise 1: Identifying LLM Limitations}



\section{LLMs tools}
Large Language Models (LLMs) have been rapidly introduced to workplace environments since ChatGPT‚Äôs breakthrough launch in late 2022. The landscape is quickly evolving, with major tech companies and AI startups releasing increasingly sophisticated models tailored for different use needs. When selecting an LLM consider factors such as data privacy policies, integration capabilities, cost structure, and specific feature sets that align with the University‚Äôs workflows. The following list covers the some of the most prominent options available today.

Microsoft Copilot copilot.microsoft.com
First Release: March 2023
Strengths: Deep integration with Microsoft Office suite
Best for: Document creation, email assistance, Office workflows, enterprise productivity
Considerations: Enterprise versions offer better data protection; requires Microsoft 365 subscription

ChatGPT (OpenAI) chat.openai.com
First Release: November 2022
Strengths: Conversational, good for general tasks, coding assistance
Best for: Writing assistance, brainstorming, general Q&A, code generation
Considerations: Data usage policies vary by version; enterprise versions available

Claude (Anthropic) claude.ai
First Release: March 2023
Strengths: Helpful, harmless, honest approach; excellent for analysis
Best for: Analysis, research assistance, ethical reasoning, document processing
Considerations: Strong focus on safety and accuracy; large context window

Google Gemini gemini.google.com
First Release: December 2023
Strengths: Multimodal capabilities, integration with Google Workspace
Best for: Research, document analysis, creative tasks, Google ecosystem integration
Considerations: Various models available (Nano, Pro, Ultra) with different capabilities

Google NotebookLM notebooklm.google.com
First Release: July 2023
Strengths: Document-grounded AI, source-based research, podcast-style audio summaries
Best for: Research analysis, document synthesis, creating audio overviews, academic work
Considerations: Works with your uploaded sources; Plus version offers 5x higher usage limits

Meta Llama llama.meta.com
First Release: February 2023
Strengths: Open-source, customizable, strong performance
Best for: Custom applications, on-premise deployment, research
Considerations: Requires technical expertise; various sizes available (7B to 405B parameters)

\subsection{Proper Attribution}
When artificial intelligence tools significantly contribute to your work, proper attribution is essential for maintaining transparency and ethical standards. Failing to acknowledge AI assistance where it played a substantial role can mislead audiences about the true nature of your work‚Äôs creation.

Example Attribution: ‚ÄúInitial drafts of this literature review were developed with assistance from Claude (Sonnet 4). All sources were independently verified, analysis was conducted by the author, and conclusions represent the author‚Äôs professional judgment.‚Äù

\section{Context matters}

\textbf{Key Takeaways}
Context is all the information you give LLMs to understand your request (role, purpose, audience, requirements)
\item Be specific, not vague - Clear context gets relevant responses; vague prompts get generic ones
\item Refine iteratively - Start basic, review output, add details, repeat until satisfied
\item Never share sensitive data - No personal records, unpublished research, or confidential information


Large Language Models work by navigating through vast embedding spaces‚Äîmultidimensional representations of knowledge and concepts. Vague or poorly defined context can lead the model to explore irrelevant areas of this space, producing generic or off-target responses. Well-crafted context act as precise navigation instructions, guiding the model to the most relevant knowledge areas and ensuring outputs that match your specific needs and context.

\subsection{Why Context Matters for LLMs}
Context is everything you provide to an LLM to help it understand your request and generate appropriate responses during your chatbot session. Without proper context, LLMs often produce generic, inaccurate, or inappropriate outputs.

Because LLMs have no memory between separate sessions, they have no inherent knowledge about who you are, your organization‚Äôs policies or the purpose of your request.

Example of poor context

Write me a report about productivity

Example of better context

I am a senior manager at the University of Bristol. I have to write a 2-page executive summary about remote work productivity for University‚Äôs department heads, focusing on evidence-based strategies and including practical implementation steps.‚Äù

Note that while LLMs have no memory between separate chat sessions and don‚Äôt retain information from previous conversations, the data you share within each individual session may still be stored by the service provider. Always follow University‚Äôs data protection policies when sharing any information.


When writing your context, never share these with AI tools:

üö´ Personal data: Student records, staff information, health data
üö´ Confidential research: Unpublished findings, grant applications under review
üö´ Commercial sensitive: Partnership agreements, financial information
üö´ Legal privileged: Legal advice, disciplinary proceedings
üö´ Security sensitive: Passwords, system configurations, access credentials

\subsection{Types of Context}
\subsubsection{Explicit Context}
Information you directly provide to the LLM, for example:

\item Your role and organization
\item The purpose of the task
\item Target audience

\subsubsection{Implicit Context}
Assumptions the LLM makes based on your prompt, for example:

\item Cultural assumptions
\item Educational level expectations
\item Language formality

\subsubsection{Making Implicit Context Explicit}
Instead of assuming the LLM will understand your context, state it clearly:

\begin{itemize}
\item Help me write a proposal on sustainable materials
\end{itemize}

Try

\begin{itemize}
\item I‚Äôm a researcher at a nanomaterial company. Help me write a 3-page research funding proposal, targeting the EPSRC, for a project on sustainable materials in engineering
\end{itemize}

\subsection{Working Within Context Limits}
LLMs have context windows, limits on how much text they can process at once or over different iterations. Some practical strategies to overcome this limitation are:

\begin{itemize}
\item Summarize lengthy background information and prioritize the most important context
\item Break complex tasks into smaller parts
\item Use previous outputs as context for follow-up requests
\end{itemize}

\subsection{Iterative Context Building}
We will not always get what we want at the first attempt. A useful strategy is starting with basic context and refine:

\begin{itemize}
\item Initial request: Provide core context
\item Review output: Identify what‚Äôs missing or wrong
\item Refine context: Add specific details or corrections
\item Iterate: Repeat until satisfactory
\end{itemize}


\subsection{Never Share Sensitive Data}

\begin{itemize}
\item üö´ Personal data: Student records, staff information, health data
\item üö´ Confidential research: Unpublished findings, grant applications under review
\item üö´ Commercial sensitive: Partnership agreements, financial information
\item üö´ Legal privileged: Legal advice, disciplinary proceedings
\item üö´ Security sensitive: Passwords, system configurations, access credentials
\end{itemize}   



\subsection{Exercise 2: Context Writing}
Transform a vague prompt into an effective, contextualised request. Use an AI tool of your choice to observe the difference that context have on your request.

Scenario: 



\section{Prompting Frameworks}

\textbf{Key Takeaways}
\begin{itemize}
\item High-quality prompts eliminate ambiguity - Clear context upfront gets better responses
\item Use structured frameworks, e.g. the CLEAR framework, to ensure complete prompts
\item Never share sensitive data - No personal records, confidential research, or security information
\end{itemize}

High-quality prompts that eliminate ambiguity are crucial for getting useful responses from Large Language Models. By providing comprehensive context upfront, you‚Äôre more likely to receive output that matches your requirements.

Scenario: You have been tasked with running a campaign to increase recruitment of European students for your University‚Äôs MSc Engineering programs.

You write the initial prompt:

Write something about recruiting students.

Problems with this prompt:

No context about the university, program, or target audience
Vague action (‚Äúwrite something‚Äù)
No specifics about format, length, or communication channel
No examples of desired output
Unclear what type of recruitment content is needed
We can use some frameworks to standardize our queries and make sure they are complete and don‚Äôt forget any relevant details. There‚Äôs no right or wrong approach ‚Äî different frameworks may work better for different AI tools and yourself, so use the one that works better for you.


\subsection{Exercise 3}
Requirements:
\begin{itemize}
\item Use the AUTOMAT framework
\item Include appropriate constraints
\item Maintain academic integrity
\end{itemize}

Reflection Questions:
\begin{itemize}
\item How do your prompts ensure AI enhances rather than replaces your expertise?
\item What verification steps would you take for each output?
\item How would you attribute AI assistance appropriately?
\end{itemize}

\section{Conversational Learning: Using AI as a learning partner, not just a task executor}

\textbf{Key Takeaways}
\begin{itemize}
Use AI as learning partner, not task executor - Ask ‚Äúwhy‚Äù and ‚Äúhow‚Äù to understand processes, not just get outputs
\item Shift from efficiency to learning mindset - Move from ‚Äúgive me the answer‚Äù to ‚Äúwalk me through the thinking‚Äù
\item Challenge AI reasoning - Test explanations, ask about limitations, play devil‚Äôs advocate
\end{itemize}

Most people approach AI with a transactional mindset, asking for document summaries, presentation outlines, email drafts, or quick recommendations. While this approach produces immediate outputs, it creates a fundamental problem: you receive results without gaining insight into the underlying processes that created them.

The learning partnership approach transforms this dynamic entirely. Instead of simply requesting outputs, you engage AI as a collaborative thinking partner. You might ask an AI to explain why it structured a summary in a particular way, what principles guided its outline choices, or how it determined the appropriate tone for professional communication. This shift in questioning style ensures that every interaction becomes an opportunity to understand processes and develop transferable skills.

The difference in outcomes is profound. Traditional approaches leave you dependent on AI for similar future tasks, while learning partnerships build your capacity to handle increasingly complex challenges independently.

\subsection{The Power of ‚ÄúWhy‚Äù Questions}
Understanding decision-making processes is at the heart of conversational learning. Rather than accepting AI outputs at face value, successful learners probe deeper into the reasoning behind recommendations. This approach reveals the thinking patterns and analytical frameworks that experts use in their fields.

Instead of just accepting AI outputs, explore the reasoning:

From	‚Üí	To
Efficiency Mindset	‚Üí	Learning Mindset
‚ÄúJust tell me what to do‚Äù	‚Üí	‚ÄúHelp me understand why this works‚Äù
‚ÄúGive me the answer‚Äù	‚Üí	‚ÄúWalk me through the thinking process‚Äù
‚ÄúWhat‚Äôs the best practice?‚Äù	‚Üí	‚ÄúWhat are the trade-offs I should consider?‚Äù
Certainty Seeking	‚Üí	Uncertainty Embracing
‚ÄúWhat‚Äôs the right answer?‚Äù	‚Üí	‚ÄúWhat factors should influence this decision?‚Äù
‚ÄúTell me the best approach‚Äù	‚Üí	‚ÄúHelp me understand the complexity of this issue‚Äù
NoteRemember
The goal isn‚Äôt to have AI solve your problems, but to help you become better at solving problems yourself. Every conversation should leave you more capable and knowledgeable than when you started.

\subsection{Learning Questions}
\textbf{Process Questions.} How did you do that?

\begin{itemize}
\item ‚ÄúWalk me through your thinking process‚Äù
\item ‚ÄúWhat steps did you follow to reach this conclusion?‚Äù
\item ‚ÄúHow did you prioritize these factors?‚Äù
\end{itemize}

\textbf{Justification Questions.} Why this approach?

\begin{itemize}
\item ‚ÄúWhat makes this approach better than alternatives?‚Äù
\item ‚ÄúWhat assumptions underlie your recommendation?‚Äù
\item ‚ÄúWhy did you emphasise this particular aspect?‚Äù
\end{itemize}

\textbf{Alternative Questions.} What else could work?

\begin{itemize}
\item ‚ÄúWhat other approaches did you consider?‚Äù
\item ‚ÄúHow would this change in different contexts?‚Äù
\item ‚ÄúWhat would you do if [constraint] existed?‚Äù
\end{itemize}

\textbf{Critical Questions.} What are the limitations?

\begin{itemize}
\item ‚ÄúWhat are the potential weaknesses of this approach?‚Äù
\item ‚ÄúWhere might this reasoning fall short?‚Äù
\item ‚ÄúWhat would a critic say about this recommendation?‚Äù
\end{itemize}

\textbf{Challenging AI Reasoning.} Don‚Äôt just accept explanations, test them.

\begin{itemize}
\item ‚ÄúWhat would happen if we did the opposite?‚Äù
\item ‚ÄúCan you think of situations where this approach would fail?‚Äù
\item ‚ÄúWhat evidence would contradict your recommendation?‚Äù
\item ‚ÄúWhat‚Äôs the worst-case scenario with this approach?‚Äù
\item ‚ÄúPlay devil‚Äôs advocate with your own suggestion‚Äù
\item ‚ÄúWhat would a skeptic say about this approach?‚Äù
\end{itemize}



\section{Privacy & Compliance}

\subsection{Compliance}

\textbf{Foundational principles:}

\begin{enumerate}
\item Business Excellence: AI should enhance, not replace, learning and critical thinking
\item Company Integrity: Transparency and honesty in all AI usage
\item Ethical Responsibility: Consideration of bias, privacy, and societal impact
\item Environmental Awareness: Sustainable and responsible technology use
\item Inclusive Innovation: Ensuring AI benefits all members of our community
\end{enumerate}

\subsection{Data Privacy and Security}
When you use AI tools for work-related tasks, whether through web interfaces, APIs, or integrated applications, your data typically:
\begin{enumerate}
\item Travels over the internet to AI company servers
\item Gets processed by AI systems you don‚Äôt control
\item May be stored temporarily or permanently by the AI provider
\item Could potentially be used for training future AI models
\item Might be subject to different legal jurisdictions
\end{enumerate}

Understanding this data flow is crucial for making informed decisions about what information you share with AI systems, especially when handling sensitive data or proprietary content. 
Always evaluate these risks

\subsection{Privacy Risk Assessment}
Before using AI tools, ask:

\textbf{Low Risk} ‚úÖ
\begin{itemize}
Public information already available online
\item General knowledge questions
\item Anonymous, aggregated data
\item Published research you‚Äôre summarizing
\end{itemize}

\textbf{Medium Risk} ‚ö†Ô∏è
\begin{itemize}
\item Internal documents with no personal data
\item Draft policies before approval
\item Academic work in progress (with proper disclosure)
\end{itemize}

\textbf{High Risk} ‚ùå
\begin{itemize}
\item Any personal or confidential information
\item Unpublished research data
Internal documents with no personal data
\item Student or staff records
\item Commercially sensitive material
\end{itemize}

\subsection{Data Protection Best Practices}
Implementing proper data protection measures helps you minimizing privacy and security risks. Consider:
\begin{enumerate}
\item Anonymize data before sharing with AI tools
\item Use placeholder data for testing and training
\item Check privacy policies of AI tools you use
\item Follow university guidelines on data classification
Consider on-premises alternatives for sensitive work
\end{enumerate}



\section{Ethics & Environmental Impact}

\textbf{Key Takeaways}
\begin{itemize}
\item Environmental cost is significant - Use AI efficiently, batch queries, choose smaller models when appropriate.
\item AI has biases - Watch for gender, racial, socioeconomic, and geographic biases; request diverse examples explicitly.
\item Maintain human oversight - AI should enhance, not replace, your expertise and critical judgment.
\item Consider ethical implications - Be mindful of data rights, labor practices, and the value of human communication.
\end{itemize}

\subsection{Environmental Impact}
We must be mindful of environmental impacts when using AI tools. AI systems consume significant energy, particularly during the initial training of large language models. For example, it is estimated that GPT-3‚Äôs training produced 85,000 kg of CO‚ÇÇ, equivalent to 112 cars running for a year.

However, the environmental cost is not a one-off event. The full life cycle of generative AI includes raw material extraction, manufacturing, training, deployment (inference), and disposal. While training is energy-intensive, the inference phase (when the user interacts with the model) can exceed the consumption and emissions from training within a matter of weeks (Luccioni et al. 2024).

Moreover, generative AI is driving a substantial increase in the need for data centers. Approximately 40$\%$ of the energy usage in data centers goes toward cooling the processing units, and this process consumes vast amounts of water. For instance, ChatGPT consumes approximately half a liter of fresh water for every chat of 20‚Äì50 prompts (Li et al. 2025).

\subsection{Water Scarcity}
Water scarcity is a major environmental crisis
Two-thirds of new data centers built in the USA since 2022 are in places already experiencing water scarcity.

Every user interaction requires computational resources. You, the user, play a role in this consumption.

Sustainable AI Practices
Given the significant consumption required for deployment/inference, focusing on efficiency is critical:

Reduce Usage:

Batch similar queries together.
Use AI for high-value tasks, not trivial ones.
Cache and reuse outputs when possible.
Choose Efficiently:

Consider the computational cost of your requests.
Avoid unnecessary regeneration of content.
You may also choose smaller models when appropriate.
Select providers committed to renewable energy.
Acknowledge the Option:

Based on ethical and environmental factors, it is acceptable if you decide not to use LLMs.
There is still value in knowing how they work and how they might be used by others.
Bias and Fairness in AI
AI systems inherit and can amplify existing societal inequalities. The existing guidance on watching for gender, racial, socioeconomic, and geographic biases remains paramount.

Gender Bias:

Associating certain professions with specific genders
Using gendered language inappropriately
Making assumptions about capabilities based on gender
Racial and Ethnic Bias:

Stereotypical associations with names or cultural references
Underrepresenting certain groups in examples
Making assumptions about backgrounds or capabilities
Socioeconomic Bias:

Assuming access to resources or opportunities
Using examples that exclude certain economic backgrounds
Privileging certain educational or professional experiences
Geographic Bias:

Focusing on Western/English-speaking perspectives
Making assumptions about local contexts
Overlooking global south perspectives
WarningBias Detection Questions
When reviewing AI outputs, ask:

Representation: Who is included and excluded in examples?
Language: Are descriptions fair and respectful to all groups?
Assumptions: What unstated assumptions are being made?
Perspectives: Whose viewpoints are prioritized?
Stereotypes: Are any harmful generalizations present?
Mitigating Bias
There are some prevention strategies that we can follow to mitigate the presence of bias in LLM answers:

Request diverse examples explicitly
Ask for multiple perspectives on controversial topics
Challenge AI outputs that seem stereotypical
Include diverse voices in your verification process
For example, instead of:

Provide examples of successful leaders,

try:

Provide examples of successful leaders from diverse backgrounds, including different genders, ethnicities, and cultural contexts, explaining their varied leadership styles.

Other Ethical Considerations
Beyond bias and environmental concerns, generative AI systems raise significant ethical questions regarding intellectual property, labor practices, and the value of human communication.

Data Rights and Labor Practices
Large language models are trained on vast datasets typically collected without explicit consent from content creators or copyright holders. This practice raises concerns about attribution, compensation, and the rights of original authors whose work contributes to model training.

Additionally, AI development relies heavily on labor that is often invisible to end users. Tasks such as Reinforcement Learning from Human Feedback (RLHF)‚Äîwhich involves rating outputs and identifying harmful content‚Äîare frequently outsourced to workers in lower-income countries who receive inadequate compensation. These patterns reflect broader inequities in how AI benefits and burdens are distributed globally.

The Value of Human Process
The appropriateness of AI use extends beyond output quality to consider the intrinsic value of human cognitive and communicative processes.

Reliability: AI-generated content may contain errors or unverifiable claims. The effort required to verify and correct outputs may exceed the effort of completing tasks independently, particularly for complex work requiring domain expertise.

Communication and respect: Using AI to generate responses to thoughtfully composed correspondence may signal that you do not value the communicative exchange equally, potentially undermining professional relationships and collegial trust.

Process versus product: Many academic contexts value the cognitive processes involved in creating work‚Äîcritical thinking, synthesis, and personal reflection‚Äînot merely the final output. Delegating these processes to AI may diminish learning and professional development outcomes.

Responsible AI use requires critical awareness of these broader implications and contextual judgment about when AI tools align with your professional values and the expectations of your academic community.



\section{Training Resources}

https://platform.openai.com/docs/guides/prompt-engineering
https://help.openai.com/en/articles/10032626-prompt-engineering-best-practices-for-chatgpt

https://platform.claude.com/docs/en/resources/prompt-library/library

https://ai.google/principles/
https://cloud.google.com/discover/what-is-prompt-engineering 
https://cloud.google.com/blog/products/application-development/five-best-practices-for-prompt-engineering 

https://www.ibm.com/think/topics/prompt-engineering 
(The 2025 Guide to Prompt Engineering: Your one-stop solution for mastering the art of prompting to unlock the full potential of AI) https://www.ibm.com/think/prompt-engineering 

https://www.promptingguide.ai/techniques 

https://www.latent.space/p/o1-skill-issue